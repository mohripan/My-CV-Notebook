{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO72EyI9YP61CCeQUSMoahA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohripan/My-CV-Notebook/blob/main/Object_Detection_Kartu_Edukasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade --force-reinstall --no-deps -q -U albumentations\n",
        "!pip install -q --upgrade --force-reinstall --no-deps -q -U opencv-python\n",
        "!pip install -q qudida"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5O7YeF2EbQw",
        "outputId": "1b2cbb4e-f654-4b4b-d865-0630888107b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtexMr-Z_up6",
        "outputId": "ae7e8110-b963-4f8e-b462-87314e6983fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp '/content/gdrive/My Drive/KaggleAPI/kaggle.json' kaggle.json\n",
        "pip install -q kaggle\n",
        "mkdir ~/.kaggle\n",
        "cp kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "kaggle datasets download -d mohammadripan/deteksi-kartu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8_hPU8M_4o4",
        "outputId": "9eceb4f4-576d-4c6e-def3-30bab7629c7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deteksi-kartu.zip to /content\n",
            " 77% 39.0M/50.6M [00:00<00:00, 74.8MB/s]\n",
            "100% 50.6M/50.6M [00:00<00:00, 78.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir kartu"
      ],
      "metadata": {
        "id": "A-dL0Ub2__4T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/deteksi-kartu.zip -d kartu"
      ],
      "metadata": {
        "id": "1l3xN1slABRu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5-G7pOOJUsB",
        "outputId": "1460c2ac-169c-48d8-fce6-a53b8c87bd9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15637, done.\u001b[K\n",
            "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 15637 (delta 123), reused 171 (delta 101), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15637/15637), 14.65 MiB | 18.93 MiB/s, done.\n",
            "Resolving deltas: 100% (10647/10647), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlr0-yx9K6-l",
        "outputId": "1565c13f-ce98-4912-a1f0-ac023fa56d8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-03 06:47:19--  https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230503T064719Z&X-Amz-Expires=300&X-Amz-Signature=4ed1a95ef595e7ffd618b1956558f5f1f3ec1a72eaa7fd28a8c7395686254bc4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-03 06:47:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230503T064719Z&X-Amz-Expires=300&X-Amz-Signature=4ed1a95ef595e7ffd618b1956558f5f1f3ec1a72eaa7fd28a8c7395686254bc4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14698491 (14M) [application/octet-stream]\n",
            "Saving to: ‘yolov5s.pt’\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.02M  45.9MB/s    in 0.3s    \n",
            "\n",
            "2023-05-03 06:47:20 (45.9 MB/s) - ‘yolov5s.pt’ saved [14698491/14698491]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import albumentations as A\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from yolov5.models.yolo import Model\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import copy"
      ],
      "metadata": {
        "id": "8xlwnTQkAWVX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/kartu/Dataset TA V1'\n",
        "anotasi = os.path.join(root_dir, 'csv.csv')\n",
        "anotasi_df = pd.read_csv(anotasi)\n",
        "anotasi_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vd2tO0mxAJoI",
        "outputId": "cf56a888-1d7d-47b0-fc1d-4262042caa17"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label_name  bbox_x  bbox_y  bbox_width  bbox_height           image_name  \\\n",
              "0       maju     555     632         568          309  20230503_053806.jpg   \n",
              "1       maju     640     765         191          131  20230503_053808.jpg   \n",
              "2       maju    1125     955         112           70  20230503_053811.jpg   \n",
              "3       maju     516     491         139           81  20230503_053815.jpg   \n",
              "4       maju     390     730         170           99  20230503_053821.jpg   \n",
              "\n",
              "   image_width  image_height  \n",
              "0         1600          1600  \n",
              "1         1600          1600  \n",
              "2         1600          1600  \n",
              "3         1600          1600  \n",
              "4         1600          1600  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfb4a36d-32e6-4a5c-b665-8a27a7000a1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_name</th>\n",
              "      <th>bbox_x</th>\n",
              "      <th>bbox_y</th>\n",
              "      <th>bbox_width</th>\n",
              "      <th>bbox_height</th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_width</th>\n",
              "      <th>image_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>maju</td>\n",
              "      <td>555</td>\n",
              "      <td>632</td>\n",
              "      <td>568</td>\n",
              "      <td>309</td>\n",
              "      <td>20230503_053806.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maju</td>\n",
              "      <td>640</td>\n",
              "      <td>765</td>\n",
              "      <td>191</td>\n",
              "      <td>131</td>\n",
              "      <td>20230503_053808.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maju</td>\n",
              "      <td>1125</td>\n",
              "      <td>955</td>\n",
              "      <td>112</td>\n",
              "      <td>70</td>\n",
              "      <td>20230503_053811.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>maju</td>\n",
              "      <td>516</td>\n",
              "      <td>491</td>\n",
              "      <td>139</td>\n",
              "      <td>81</td>\n",
              "      <td>20230503_053815.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>maju</td>\n",
              "      <td>390</td>\n",
              "      <td>730</td>\n",
              "      <td>170</td>\n",
              "      <td>99</td>\n",
              "      <td>20230503_053821.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfb4a36d-32e6-4a5c-b665-8a27a7000a1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfb4a36d-32e6-4a5c-b665-8a27a7000a1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfb4a36d-32e6-4a5c-b665-8a27a7000a1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out only image files (with .jpg extension)\n",
        "image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]"
      ],
      "metadata": {
        "id": "nSPS8_xuAn0J"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_image = random.choice(image_files)\n",
        "\n",
        "# Read the image and its annotation\n",
        "img = Image.open(os.path.join(root_dir, random_image))\n",
        "annotation = anotasi_df[anotasi_df['image_name'] == random_image]\n",
        "\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iLjwwU3XC3-",
        "outputId": "aeeb3967-4bb4-4b55-f976-c865b275abbe"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe865f613c0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an image\n",
        "random_image = random.choice(image_files)\n",
        "\n",
        "# Read the image and its annotation\n",
        "img = Image.open(os.path.join(root_dir, random_image))\n",
        "annotation = anotasi_df[anotasi_df['image_name'] == random_image]\n",
        "\n",
        "# Plot the image\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "\n",
        "# Draw bounding boxes\n",
        "for index, row in annotation.iterrows():\n",
        "    bbox_x, bbox_y, bbox_width, bbox_height = row['bbox_x'], row['bbox_y'], row['bbox_width'], row['bbox_height']\n",
        "    rect = patches.Rectangle((bbox_x, bbox_y), bbox_width, bbox_height, linewidth=1, edgecolor='r', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5mHYbuJ_BYmc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "train_df, dev_test_df = train_test_split(anotasi_df, test_size=0.2, random_state=42)\n",
        "dev_df, test_df = train_test_split(dev_test_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Save the train/dev/test sets as CSV files\n",
        "train_df.to_csv(os.path.join(root_dir, 'train.csv'), index=False)\n",
        "dev_df.to_csv(os.path.join(root_dir, 'dev.csv'), index=False)\n",
        "test_df.to_csv(os.path.join(root_dir, 'test.csv'), index=False)"
      ],
      "metadata": {
        "id": "Mc05hbi6GeP0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transforms=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def is_valid_bbox(self, bbox):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        return x_max > x_min and y_max > y_min\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx]['image_name'])\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        bbox = self.dataframe.iloc[idx][['bbox_x', 'bbox_y', 'bbox_width', 'bbox_height']].values\n",
        "        label = self.dataframe.iloc[idx]['label_name']\n",
        "\n",
        "        sample = {'image': image, 'bbox': bbox, 'label': label}\n",
        "\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=np.array(image), bboxes=[bbox], labels=[label])\n",
        "\n",
        "            # Check if the transformed bbox has valid coordinates\n",
        "            if len(transformed['bboxes']) > 0 and self.is_valid_bbox(transformed['bboxes'][0]):\n",
        "                sample['image'] = transformed['image']\n",
        "                sample['bbox'] = transformed['bboxes'][0]\n",
        "            else:\n",
        "                return self.__getitem__(random.randint(0, len(self.dataframe) - 1))\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "lNiLafNbBkG3"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Albumentations transformations for the train dataset\n",
        "train_transformations = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "    A.Resize(height=224, width=224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    A.pytorch.ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='coco', label_fields=['labels'], min_visibility=0.2, min_area=100))\n",
        "\n",
        "# Define Albumentations transformations for the dev and test datasets\n",
        "dev_test_transformations = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='coco', label_fields=['labels']))\n",
        "\n",
        "# Create the datasets with different transformations\n",
        "train_dataset = CustomDataset(train_df, root_dir, transforms=train_transformations)\n",
        "dev_dataset = CustomDataset(dev_df, root_dir, transforms=dev_test_transformations)\n",
        "test_dataset = CustomDataset(test_df, root_dir, transforms=dev_test_transformations)"
      ],
      "metadata": {
        "id": "TdBpnJmoFAbc"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_init_fn(worker_id):\n",
        "    worker_info = torch.utils.data.get_worker_info()\n",
        "    dataset = worker_info.dataset\n",
        "    dataset.worker_id = worker_id"
      ],
      "metadata": {
        "id": "eddw36jYUobU"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0, worker_init_fn=worker_init_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=4, shuffle=False, num_workers=0, worker_init_fn=worker_init_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0, worker_init_fn=worker_init_fn)"
      ],
      "metadata": {
        "id": "leDD1VqWFC7v"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(tensor):\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
        "    return (tensor * std) + mean\n",
        "\n",
        "def plot_batch(images, bboxes):\n",
        "    images = denormalize(images).permute(0, 2, 3, 1).numpy()\n",
        "    fig, axs = plt.subplots(1, len(images), figsize=(15, 15))\n",
        "\n",
        "    for i, (image, bbox) in enumerate(zip(images, bboxes)):\n",
        "        axs[i].imshow(image)\n",
        "        bbox_x, bbox_y, bbox_width, bbox_height = bbox\n",
        "        rect = patches.Rectangle((bbox_x, bbox_y), bbox_width, bbox_height, linewidth=1, edgecolor='r', facecolor='none')\n",
        "        axs[i].add_patch(rect)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iPfzmIX7Gpg3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolov5_loss(output, target, anchors, num_classes):\n",
        "    # Extract number of anchor boxes per detection layer\n",
        "    num_anchors = [len(a) for a in anchors]\n",
        "    \n",
        "    # Split output into separate detection layers\n",
        "    output = torch.split(output, num_anchors, dim=1)\n",
        "    \n",
        "    # Split target into separate detection layers\n",
        "    target = [t.view(t.size(0), len(a), -1) for t, a in zip(target, anchors)]\n",
        "    \n",
        "    # Compute loss for each detection layer\n",
        "    loss = 0\n",
        "    for i, (pred, tgt, a) in enumerate(zip(output, target, anchors)):\n",
        "        b, _, ny, nx = pred.size()\n",
        "        na = len(a)\n",
        "        stride = 1 / nx\n",
        "        \n",
        "        # Split prediction into bounding box, objectness, and class probability predictions\n",
        "        pred = pred.view(b, na, -1, ny, nx)\n",
        "        pred_boxes = pred[:, :, :4, :, :]  # x, y, w, h\n",
        "        pred_obj = pred[:, :, 4:5, :, :]\n",
        "        pred_cls = pred[:, :, 5:, :, :]\n",
        "        \n",
        "        # Split target into bounding box, objectness, and class probability targets\n",
        "        tgt_boxes = tgt[:, :, :4, :, :]  # x, y, w, h\n",
        "        tgt_obj = tgt[:, :, 4:5, :, :]\n",
        "        tgt_cls = tgt[:, :, 5:, :, :]\n",
        "        \n",
        "        # Compute mask for active anchor boxes\n",
        "        obj_mask = tgt_obj > 0\n",
        "        noobj_mask = tgt_obj == 0\n",
        "        \n",
        "        # Compute objectness loss\n",
        "        obj_loss = F.binary_cross_entropy_with_logits(pred_obj[obj_mask], tgt_obj[obj_mask])\n",
        "        noobj_loss = F.binary_cross_entropy_with_logits(pred_obj[noobj_mask], tgt_obj[noobj_mask])\n",
        "        loss += obj_loss + 100 * noobj_loss\n",
        "        \n",
        "        # Compute bounding box loss\n",
        "        box_loss = F.mse_loss(pred_boxes[obj_mask], tgt_boxes[obj_mask])\n",
        "        loss += box_loss\n",
        "        \n",
        "        # Compute class probability loss\n",
        "        cls_loss = F.binary_cross_entropy_with_logits(pred_cls[obj_mask], tgt_cls[obj_mask])\n",
        "        loss += cls_loss\n",
        "    \n",
        "    return loss"
      ],
      "metadata": {
        "id": "v46jw_ClNgNu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the pre-trained YOLOv5 model\n",
        "model = torch.load(\"yolov5s.pt\")[\"model\"]\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wJvC5_OGx_r",
        "outputId": "5195949a-d75e-40ed-86e2-da1738b4c6c2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetectionModel(\n",
              "  (model): Sequential(\n",
              "    (0): Conv(\n",
              "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (1): Conv(\n",
              "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (2): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Conv(\n",
              "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (4): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): Conv(\n",
              "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (6): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): Conv(\n",
              "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (8): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): SPPF(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (10): Conv(\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (12): Concat()\n",
              "    (13): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (14): Conv(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (16): Concat()\n",
              "    (17): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (18): Conv(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (19): Concat()\n",
              "    (20): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (21): Conv(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (22): Concat()\n",
              "    (23): C3(\n",
              "      (cv1): Conv(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv2): Conv(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (cv3): Conv(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU()\n",
              "      )\n",
              "      (m): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (24): Detect(\n",
              "      (m): ModuleList(\n",
              "        (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(train_df['label_name']))\n",
        "\n",
        "# Modify the last layer to match the number of classes in your dataset\n",
        "model.model[-1].nc = num_classes\n",
        "device = next(model.parameters()).device\n",
        "model.model[-1].anchors = model.model[-1].anchors.to(device)\n",
        "\n",
        "# Fine-tune only the last layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.model[-1].parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "aW4pabEEKLdO"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = yolov5_loss\n",
        "optimizer = Adam(model.model[-1].parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 50\n",
        "best_model = None\n",
        "best_val_loss = float('inf')"
      ],
      "metadata": {
        "id": "-It1uwNULXVM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coco_to_yolo(targets, num_classes):\n",
        "    yolo_targets = []\n",
        "    for t in targets:\n",
        "        # Convert the bounding box format (x, y, w, h) to (x1, y1, x2, y2)\n",
        "        print(t['boxes'])\n",
        "        x1, y1, w, h = t[\"boxes\"]\n",
        "        x2, y2 = x1 + w, y1 + h\n",
        "        bbox = [x1, y1, x2, y2]\n",
        "\n",
        "        # Convert the class label to one-hot encoding\n",
        "        cls = t[\"labels\"]\n",
        "        one_hot = [0] * num_classes\n",
        "        one_hot[cls] = 1\n",
        "\n",
        "        yolo_targets.append({\"bbox\": bbox, \"cls\": one_hot})\n",
        "    return yolo_targets"
      ],
      "metadata": {
        "id": "R5PJe44vNMm1"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_model = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "metadata": {
        "id": "nmaa7_FqRz-j"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        images = batch['image']\n",
        "        targets = batch['bbox']\n",
        "\n",
        "        # Convert COCO format targets to YOLOv5 format\n",
        "        yolo_targets = coco_to_yolo(targets, num_classes)\n",
        "\n",
        "        # Move tensors to the device the model is using\n",
        "        device = next(model.parameters()).device\n",
        "        images = images.to(device)\n",
        "        yolo_targets = [{k: v.to(device) for k, v in t.items()} for t in yolo_targets]\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images, yolo_targets)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dev_loader:\n",
        "            images = batch['image']\n",
        "            targets = batch['bbox']\n",
        "\n",
        "            # Convert COCO format targets to YOLOv5 format\n",
        "            yolo_targets = coco_to_yolo(targets, num_classes)\n",
        "\n",
        "            # Move tensors to the device the model is using\n",
        "            device = next(model.parameters()).device\n",
        "            images = images.to(device)\n",
        "            yolo_targets = [{k: v.to(device) for k, v in t.items()} for t in yolo_targets]\n",
        "            # Forward pass\n",
        "            outputs = model(images, targets)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(dev_loader)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "# Save the best model\n",
        "torch.save(best_model.state_dict(), \"best_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYjs2RX_R5TR",
        "outputId": "91f5db84-f092-4296-c8bc-02090dac8f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4j1j4kiSkxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}